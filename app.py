
import os, glob, io, zipfile, re, base64, requests
import streamlit as st
import pandas as pd

st.set_page_config(page_title="ğŸŠâ€â™€ï¸ æ¸¸æ³³æˆç»©æŸ¥è¯¢ç³»ç»Ÿï¼ˆèµ›äº‹æ–‡ä»¶å¤¹ + è¡¨å• + GitHubæäº¤ï¼‰", layout="wide")

HELP = """
**èµ›äº‹æ–‡ä»¶å¤¹å‘½åï¼ˆå»ºè®®ï¼‰**ï¼š`meets/YYYY-MM-DD_City/`  
**meta.csv åˆ—**ï¼ˆé¡ºåºéšæ„ï¼Œåˆ—åå¿…é¡»ä¸€è‡´ï¼‰ï¼š`Date, City, MeetName, PoolName, LengthMeters`  
**results.csv åˆ—**ï¼š`Name, EventName, Result, Rank, Note`  
> ç¨‹åºæŒ‰**åˆ—å**è¯»å–ï¼Œä¸ä¾èµ–åˆ—é¡ºåºã€‚`Result` å»ºè®®ç”¨ `mm:ss` æˆ– `mm:ss.ms`ï¼ˆå¦‚ `01:02.45`ï¼‰ã€‚
"""

st.title("ğŸŠâ€â™€ï¸ æ¸¸æ³³æˆç»©æŸ¥è¯¢ç³»ç»Ÿ")
st.caption(HELP)

# ----------------- helpers -----------------
def parse_time_to_seconds(ts: str):
    """æ”¯æŒ mm:ss æˆ– mm:ss.xxxï¼ˆæ¯«ç§’/ç™¾åˆ†ç§’ï¼‰"""
    if not isinstance(ts, str):
        return None
    ts = ts.strip()
    if not ts:
        return None
    try:
        if ":" in ts:
            m, s = ts.split(":", 1)   # å…è®¸ s éƒ¨åˆ†å¸¦å°æ•°
            return int(m) * 60 + float(s)
        return float(ts)
    except Exception:
        return None

def load_all_meets(base_dir="meets"):
    rows = []
    for folder in sorted(glob.glob(os.path.join(base_dir, "*"))):
        meta_path = os.path.join(folder, "meta.csv")
        res_path  = os.path.join(folder, "results.csv")
        if os.path.isfile(meta_path) and os.path.isfile(res_path):
            try:
                meta = pd.read_csv(meta_path)
                res  = pd.read_csv(res_path)
                required_meta = ["Date","City","MeetName","PoolName","LengthMeters"]
                required_res  = ["Name","EventName","Result","Rank","Note"]
                if not all(col in meta.columns for col in required_meta):
                    st.warning(f"{folder} çš„ meta.csv åˆ—åä¸å®Œæ•´ï¼Œè¯·åŒ…å«ï¼š{required_meta}")
                    continue
                if not all(col in res.columns for col in required_res):
                    st.warning(f"{folder} çš„ results.csv åˆ—åä¸å®Œæ•´ï¼Œè¯·åŒ…å«ï¼š{required_res}")
                    continue
                meta = meta[required_meta].copy()
                res  = res[required_res].copy()
                merged = res.assign(**{col: meta.iloc[0][col] for col in required_meta})
                merged["MeetKey"] = os.path.basename(folder)
                rows.append(merged)
            except Exception as e:
                st.warning(f"è¯»å– {folder} å‡ºé”™ï¼š{e}")
                continue
    if rows:
        df = pd.concat(rows, ignore_index=True)
        df["LengthMeters"] = pd.to_numeric(df["LengthMeters"], errors="coerce").fillna(0).astype(int)
        df["Seconds"] = df["Result"].apply(parse_time_to_seconds)
        return df
    return pd.DataFrame(columns=["Name","EventName","Result","Rank","Note","Date","City","MeetName","PoolName","LengthMeters","MeetKey","Seconds"])

# ---- GitHub helpers ----
def have_github_secrets():
    needed = ["GITHUB_TOKEN", "REPO"]
    missing = [k for k in needed if k not in st.secrets]
    return len(missing) == 0, missing

def gh_put(path, content_bytes, message):
    token  = st.secrets["GITHUB_TOKEN"]
    repo   = st.secrets["REPO"]
    branch = st.secrets.get("BRANCH", "main")

    headers = {
        "Authorization": f"token {token}",
        "Accept": "application/vnd.github+json",
    }
    url = f"https://api.github.com/repos/{repo}/contents/{path}"

    # check existing file to get sha
    r = requests.get(url, headers=headers, params={"ref": branch})
    sha = r.json().get("sha") if r.status_code == 200 else None

    payload = {
        "message": message,
        "content": base64.b64encode(content_bytes).decode(),
        "branch": branch
    }
    if sha:
        payload["sha"] = sha

    resp = requests.put(url, headers=headers, json=payload, timeout=30)
    if not resp.ok:
        raise RuntimeError(f"GitHub API é”™è¯¯ï¼š{resp.status_code} {resp.text}")
    return resp.json()

def sanitize_folder_name(date_str, city):
    # Keep date as-is, sanitize city (letters, numbers, underscore/dash allowed)
    city_clean = re.sub(r"[^A-Za-z0-9_\-]", "", str(city).strip().replace(" ", ""))
    return f"{date_str}_{city_clean}"

# ----------------- tabs -----------------
tab1, tab2 = st.tabs(["ğŸ“Š æµè§ˆ/åˆ†æ", "â• è¡¨å•å½•å…¥ï¼ˆç”Ÿæˆèµ›äº‹å¹¶å¯è‡ªåŠ¨æäº¤åˆ° GitHubï¼‰"])

with tab1:
    data = load_all_meets()
    if data.empty:
        st.info("meets/ ç›®å½•ä¸‹æš‚æœªå‘ç°æœ‰æ•ˆèµ›äº‹æ–‡ä»¶å¤¹ã€‚è¯·åˆ°â€œè¡¨å•å½•å…¥â€æ ‡ç­¾é¡µæ–°å»ºï¼Œæˆ–æ‰‹åŠ¨ä¸Šä¼ ã€‚")
    else:
        # Filters
        all_names = sorted(data["Name"].dropna().unique())
        sel_names = st.multiselect("Nameï¼ˆå¯å¤šé€‰ï¼‰", all_names, default=["Anna"] if "Anna" in all_names else all_names)

        events = ["All"] + sorted(data["EventName"].dropna().unique())
        sel_event = st.selectbox("Event", events)

        lengths = ["All"] + sorted(data["LengthMeters"].unique().tolist())
        sel_len = st.selectbox("Length (Meters)", lengths)

        pools = ["All"] + sorted(data["PoolName"].dropna().unique())
        sel_pool = st.selectbox("Pool Name", pools)

        cities = ["All"] + sorted(data["City"].dropna().unique())
        sel_city = st.selectbox("City", cities)

        dates = ["All"] + sorted(data["Date"].dropna().unique())
        sel_date = st.selectbox("Date", dates)

        meets = ["All"] + sorted(data["MeetName"].dropna().unique())
        sel_meet = st.selectbox("Meet Name", meets)

        df = data.copy()
        if sel_names: df = df[df["Name"].isin(sel_names)]
        if sel_event != "All": df = df[df["EventName"] == sel_event]
        if sel_len   != "All": df = df[df["LengthMeters"] == sel_len]
        if sel_pool  != "All": df = df[df["PoolName"] == sel_pool]
        if sel_city  != "All": df = df[df["City"] == sel_city]
        if sel_date  != "All": df = df[df["Date"] == sel_date]
        if sel_meet  != "All": df = df[df["MeetName"] == sel_meet]

        st.subheader("ğŸ… æ¯”èµ›è®°å½•")
        st.dataframe(df)

        # Seed highlight logic
        if not df.empty:
            palette = ["red","blue","green","purple","orange","brown","teal","magenta","olive","navy"]
            name_order = sel_names if sel_names else all_names
            name_colors = {name: palette[i % len(palette)] for i, name in enumerate(name_order)}

            tmp = df.copy()
            group_cols = ["Name","LengthMeters"] if sel_event != "All" else ["Name","EventName","LengthMeters"]
            tmp["BestSeconds"] = tmp.groupby(group_cols)["Seconds"].transform("min")
            tmp["IsBest"] = tmp["Seconds"] == tmp["BestSeconds"]
            disp = tmp[["Name","EventName","Result","Rank","Note","PoolName","City","LengthMeters","Date"]]

            def style_row(row):
                styles = []
                is_best = tmp.loc[row.name, "IsBest"]
                for col in disp.columns:
                    if col == "Result" and is_best:
                        styles.append(f"color: {name_colors.get(row['Name'], 'black')}")
                    else:
                        styles.append("")
                return styles

            styled = disp.style.apply(style_row, axis=1).hide_index()
            st.markdown("**è¯´æ˜ï¼šæ¯ä½é€‰æ‰‹åœ¨ä¸åŒæ³³æ± é•¿åº¦ï¼ˆæˆ–ä¸åŒé¡¹ç›®Ã—é•¿åº¦ï¼‰ä¸‹çš„æœ€ä½³æˆç»©å·²ç”¨è¯¥é€‰æ‰‹çš„å›ºå®šé¢œè‰²é«˜äº®åœ¨ Result åˆ—ã€‚**")
            st.write(styled.to_html(escape=False), unsafe_allow_html=True)

            st.subheader("ğŸ“ˆ æˆç»©æŠ˜çº¿å›¾ï¼ˆå•ä½ï¼šç§’ï¼‰")
            chart_df = tmp.pivot_table(index="Date", columns="Name", values="Seconds", aggfunc="min")
            st.line_chart(chart_df)

        st.download_button("ğŸ“¥ ä¸‹è½½å½“å‰ç­›é€‰ç»“æœ", df.to_csv(index=False).encode("utf-8-sig"), file_name="filtered_results.csv")

with tab2:
    st.subheader("æ­¥éª¤ 1ï¼šå¡«å†™èµ›äº‹ä¿¡æ¯ï¼ˆmeta.csvï¼‰")
    with st.form("meta_form", clear_on_submit=False):
        date_val = st.date_input("Dateï¼ˆæ—¥æœŸï¼‰")
        city_val = st.text_input("Cityï¼ˆåŸå¸‚ï¼‰", placeholder="ChiangMai")
        meet_name = st.text_input("MeetNameï¼ˆèµ›äº‹åç§°ï¼‰", placeholder="Chiang Open")
        pool_name = st.text_input("PoolNameï¼ˆæ³³æ± åï¼‰", placeholder="Kawila")
        length_val = st.selectbox("LengthMetersï¼ˆæ³³æ± é•¿åº¦ï¼‰", [25, 50])
        meta_submitted = st.form_submit_button("ä¿å­˜èµ›äº‹ä¿¡æ¯")
    if meta_submitted:
        st.session_state["meta"] = {
            "Date": str(date_val),
            "City": city_val.strip(),
            "MeetName": meet_name.strip(),
            "PoolName": pool_name.strip(),
            "LengthMeters": int(length_val),
        }
        st.success("âœ… å·²ä¿å­˜èµ›äº‹ä¿¡æ¯")
        st.table(pd.DataFrame([st.session_state["meta"]]))

    st.markdown("---")
    st.subheader("æ­¥éª¤ 2ï¼šå½•å…¥æˆç»©ï¼ˆresults.csvï¼‰")
    default_events = [
        "25m Freestyle","25m Backstroke","25m Breaststroke","25m Butterfly",
        "50m Freestyle","50m Backstroke","50m Breaststroke","50m Butterfly",
        "100m Freestyle","100m Backstroke","100m Breaststroke","100m Butterfly",
        "200m Freestyle","200m Backstroke","200m Breaststroke","200m Butterfly",
        "400m Freestyle"
    ]

    if "result_rows" not in st.session_state:
        st.session_state["result_rows"] = 1
    cols = st.columns(3)
    if cols[0].button("â• æ·»åŠ ä¸€è¡Œ"):
        st.session_state["result_rows"] += 1
    if cols[1].button("â– åˆ é™¤ä¸€è¡Œ") and st.session_state["result_rows"] > 1:
        st.session_state["result_rows"] -= 1
    st.caption(f"å½“å‰è¡Œæ•°ï¼š{st.session_state['result_rows']}")

    results_rows = []
    with st.form("results_form", clear_on_submit=False):
        for i in range(st.session_state["result_rows"]):
            st.markdown(f"**è®°å½• {i+1}**")
            c1, c2, c3, c4, c5 = st.columns([1.2,1.4,1,0.8,1.2])
            name_i = c1.text_input(f"Name_{i}", key=f"name_{i}")
            ev_choice = c2.selectbox(f"Event_{i}", options=["ï¼ˆè‡ªå®šä¹‰ï¼‰"] + default_events, key=f"event_{i}")
            custom_event = ""
            if ev_choice == "ï¼ˆè‡ªå®šä¹‰ï¼‰":
                custom_event = c2.text_input(f"è‡ªå®šä¹‰é¡¹ç›®_{i}", key=f"cust_event_{i}", placeholder="100m IM ç­‰")
            result_i = c3.text_input(f"Result_{i}", key=f"result_{i}", placeholder="mm:ss æˆ– mm:ss.msï¼Œæ¯”å¦‚ 01:02.45")
            rank_i = c4.number_input(f"Rank_{i}", key=f"rank_{i}", min_value=0, step=1)
            note_i = c5.text_input(f"Note_{i}", key=f"note_{i}", placeholder="å¯ç•™ç©º")

            final_event = custom_event.strip() if ev_choice == "ï¼ˆè‡ªå®šä¹‰ï¼‰" else ev_choice
            results_rows.append({
                "Name": name_i.strip(),
                "EventName": final_event,
                "Result": result_i.strip(),
                "Rank": int(rank_i) if rank_i is not None else 0,
                "Note": note_i.strip(),
            })

        auto_push = st.checkbox("âœ… æäº¤åˆ° GitHubï¼ˆå…ä¸‹è½½ä¸Šä¼ ï¼‰", value=False,
                                help="éœ€è¦åœ¨ Streamlit Secrets é‡Œé…ç½® GITHUB_TOKENã€REPOï¼ˆå’Œå¯é€‰çš„ BRANCHï¼‰ã€‚")
        also_write_local = st.checkbox("åŒæ—¶ä¿å­˜åˆ°æœ¬åœ° meets/ ç›®å½•ï¼ˆè°ƒè¯•ç”¨ï¼‰", value=False)
        gen = st.form_submit_button("ç”Ÿæˆ/æäº¤")

    if gen:
        if "meta" not in st.session_state:
            st.error("è¯·å…ˆå®Œæˆâ€œæ­¥éª¤ 1ï¼šå¡«å†™èµ›äº‹ä¿¡æ¯â€ã€‚")
        else:
            meta = st.session_state["meta"]
            if not meta["Date"] or not meta["City"] or not meta["MeetName"]:
                st.error("æ—¥æœŸ / åŸå¸‚ / èµ›äº‹åç§° ä¸èƒ½ä¸ºç©º")
                st.stop()
            clean_rows = [r for r in results_rows if r["Name"] and r["EventName"] and r["Result"]]
            if not clean_rows:
                st.error("è¯·è‡³å°‘å¡«å†™ä¸€æ¡å®Œæ•´çš„æˆç»©è®°å½•ï¼ˆNameã€Eventã€Result å¿…å¡«ï¼‰ã€‚")
                st.stop()

            meta_df = pd.DataFrame([meta], columns=["Date","City","MeetName","PoolName","LengthMeters"])
            results_df = pd.DataFrame(clean_rows, columns=["Name","EventName","Result","Rank","Note"])

            folder_key = sanitize_folder_name(meta["Date"], meta["City"])
            # æœ¬åœ°ä¿å­˜ï¼ˆå¯é€‰ï¼‰
            if also_write_local:
                local_dir = os.path.join("meets", folder_key)
                os.makedirs(local_dir, exist_ok=True)
                meta_df.to_csv(os.path.join(local_dir, "meta.csv"), index=False, encoding="utf-8-sig")
                results_df.to_csv(os.path.join(local_dir, "results.csv"), index=False, encoding="utf-8-sig")
                st.success(f"å·²å†™å…¥æœ¬åœ°ï¼š{local_dir}/meta.csv, results.csv")

            # GitHub æäº¤æˆ–ç”ŸæˆZIP
            if auto_push:
                ok, missing = have_github_secrets()
                if not ok:
                    st.error(f"ç¼ºå°‘ Secretsï¼š{missing}ã€‚è¯·åœ¨ Streamlit Cloud - App - Settings - Secrets ä¸­é…ç½®ã€‚")
                else:
                    try:
                        folder = f"meets/{folder_key}"
                        r1 = gh_put(f"{folder}/meta.csv", meta_df.to_csv(index=False).encode("utf-8-sig"),
                                    f"Add meta for {folder_key}")
                        r2 = gh_put(f"{folder}/results.csv", results_df.to_csv(index=False).encode("utf-8-sig"),
                                    f"Add results for {folder_key}")
                        st.success("âœ… å·²æäº¤åˆ° GitHubï¼ä»“åº“æ”¶åˆ°æ–°æ–‡ä»¶åä¼šè‡ªåŠ¨è§¦å‘é‡éƒ¨ç½²ï¼Œç¨ç­‰ç‰‡åˆ»åˆ·æ–°å³å¯çœ‹åˆ°æœ€æ–°æ•°æ®ã€‚")
                        st.markdown(f"[æŸ¥çœ‹ meta.csv]({r1.get('content',{}).get('html_url','')})  |  [æŸ¥çœ‹ results.csv]({r2.get('content',{}).get('html_url','')})")
                    except Exception as e:
                        st.error(f"æäº¤å¤±è´¥ï¼š{e}")
            else:
                zip_buffer = io.BytesIO()
                with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as z:
                    z.writestr(f"meets/{folder_key}/meta.csv", meta_df.to_csv(index=False, encoding="utf-8-sig"))
                    z.writestr(f"meets/{folder_key}/results.csv", results_df.to_csv(index=False, encoding="utf-8-sig"))
                st.success(f"âœ… å·²ç”Ÿæˆèµ›äº‹æ–‡ä»¶å¤¹ï¼šmeets/{folder_key}/ ï¼ˆå†…å« meta.csv ä¸ results.csvï¼‰")
                st.download_button("ğŸ“¦ ä¸‹è½½ ZIPï¼ˆæ‰‹åŠ¨ä¸Šä¼ åˆ° GitHubï¼‰", data=zip_buffer.getvalue(),
                                   file_name=f"{folder_key}.zip", mime="application/zip")

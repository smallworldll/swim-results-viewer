# -*- coding: utf-8 -*-
"""
Swim Results (Meet Mode) - Stable build
- No EventName in meta (MeetName/PoolName required; Length 25/50)
- After save: clear inputs & rerun (using safe_rerun for new Streamlit)
- Deletions/edits/new rows: save locally AND auto-push to GitHub (if secrets present)
- Dedup writes to avoid accidental double-saves
- Results shown shortest time first; global query with filters
"""

from __future__ import annotations
import re, json, base64
from datetime import date, datetime
from pathlib import Path
from typing import List, Tuple, Optional

import numpy as np
import pandas as pd
import requests
import streamlit as st

# ---------------- Setup ----------------
st.set_page_config(page_title="æ¸¸æ³³æˆç»©ç³»ç»Ÿï¼ˆèµ›äº‹åˆ¶ï¼‰", layout="wide", initial_sidebar_state="expanded")
APP_TITLE = "ğŸŠâ€â™€ï¸ æ¸¸æ³³æˆç»©ç³»ç»Ÿï¼ˆèµ›äº‹åˆ¶ï¼‰"
MEETS_ROOT = Path("meets")
MEETS_ROOT.mkdir(parents=True, exist_ok=True)

# ------------- Compatibility -------------
def safe_rerun():
    """Streamlit rerun across versions."""
    if hasattr(st, "rerun"):
        st.rerun()
    elif hasattr(st, "experimental_rerun"):
        st.experimental_rerun()

# ------------- Time helpers -------------
TIME_RE = re.compile(r"^\s*(?:(\d{1,2}):)?(\d{1,2})(?:[.:](\d{1,2}))?\s*$")

def parse_time_to_seconds(s: str) -> Optional[float]:
    """Accept '34.12' or '0:34.12' or '1:05.3' -> seconds(float)."""
    if not isinstance(s, str):
        return None
    s = s.strip().replace("ï¼š", ":").replace("ï¼Œ", ".")
    if not s:
        return None
    m = TIME_RE.match(s)
    if not m:
        return None
    mm = int(m.group(1)) if m.group(1) else 0
    ss = int(m.group(2))
    ff = m.group(3)
    hundredths = int(ff) if ff else 0
    if ff and len(ff) == 1:
        hundredths *= 10
    return mm * 60 + ss + hundredths / 100.0

def seconds_to_mssxx(sec: Optional[float]) -> str:
    if sec is None or (isinstance(sec, float) and np.isnan(sec)):
        return ""
    sec = float(sec)
    m = int(sec // 60)
    s = sec - m * 60
    whole = int(s)
    hund = int(round((s - whole) * 100))
    if hund == 100:
        hund = 0
        whole += 1
        if whole == 60:
            whole = 0
            m += 1
    return f"{m}:{whole:02d}.{hund:02d}"

# ------------- GitHub push -------------
def _gh_headers(token: str):
    return {"Authorization": f"Bearer {token}", "Accept": "application/vnd.github+json"}

def push_to_github(path_in_repo: str, content: bytes, message: str) -> Tuple[bool, str]:
    """Create/update a file at path_in_repo (e.g., 'meets/2025-08-09_X_Y/meta.csv')."""
    repo = st.secrets.get("REPO", "")
    token = st.secrets.get("GITHUB_TOKEN", "")
    if not repo or not token:
        st.info("âš ï¸ æœªé…ç½® GITHUB_TOKEN/REPOï¼Œå·²è·³è¿‡ GitHub æ¨é€ï¼ˆæœ¬åœ°å·²ä¿å­˜ï¼‰ã€‚")
        return False, "NO_SECRET"
    url = f"https://api.github.com/repos/{repo}/contents/{path_in_repo}"
    headers = _gh_headers(token)
    # check if exists for sha
    r = requests.get(url, headers=headers, timeout=15)
    sha = r.json().get("sha") if r.status_code == 200 else None
    payload = {
        "message": message,
        "content": base64.b64encode(content).decode("utf-8"),
        "branch": "main",
    }
    if sha:
        payload["sha"] = sha
    r2 = requests.put(url, headers=headers, data=json.dumps(payload), timeout=20)
    if r2.status_code in (200,201):
        return True, "OK"
    try:
        return False, f"{r2.status_code} {r2.json()}"
    except Exception:
        return False, str(r2.status_code)

# ------------- IO helpers -------------
def sanitize(s: str) -> str:
    return re.sub(r"\s+", " ", str(s)).replace("/", "_").strip()

def meet_folder_name(date_str: str, city: str, pool: str) -> str:
    return f"{date_str}_{sanitize(city)}_{sanitize(pool)}"

def list_meets_sorted() -> List[Path]:
    items = [p for p in MEETS_ROOT.iterdir() if p.is_dir() and (p / "meta.csv").exists()]
    def k(p: Path):
        try:
            return datetime.strptime(p.name.split("_",1)[0], "%Y-%m-%d")
        except Exception:
            return datetime.min
    return sorted(items, key=k, reverse=True)

def load_meta(meet_dir: Path) -> pd.Series:
    p = meet_dir / "meta.csv"
    if not p.exists():
        return pd.Series(dtype=object)
    df = pd.read_csv(p)
    return df.iloc[0] if not df.empty else pd.Series(dtype=object)

def save_meta_and_push(date_str: str, city: str, meet: str, pool: str, length: int) -> Path:
    folder = meet_folder_name(date_str, city, pool)
    meet_dir = MEETS_ROOT / folder
    meet_dir.mkdir(parents=True, exist_ok=True)
    meta = pd.DataFrame([{
        "Date": date_str,
        "City": city,
        "MeetName": meet,
        "PoolName": pool,
        "LengthMeters": int(length),
    }])[["Date","City","MeetName","PoolName","LengthMeters"]]
    meta_path = meet_dir / "meta.csv"
    meta.to_csv(meta_path, index=False, encoding="utf-8-sig")
    # push
    push_to_github(str(meta_path).replace("\\","/"), meta_path.read_bytes(), f"Save meta for {folder}")
    return meet_dir

def load_results(meet_dir: Path) -> pd.DataFrame:
    p = meet_dir / "results.csv"
    if not p.exists():
        return pd.DataFrame(columns=["Name","EventName","Result","Rank","Note","Seconds",
                                     "Date","City","MeetName","PoolName","LengthMeters"])
    df = pd.read_csv(p)
    if "Seconds" not in df.columns and "Result" in df.columns:
        df["Seconds"] = df["Result"].map(parse_time_to_seconds)
    return df

def write_results_and_push(meet_dir: Path, df: pd.DataFrame, message: str):
    p = meet_dir / "results.csv"
    df = df.copy()
    # normalize time columns
    df["Seconds"] = df["Seconds"] if "Seconds" in df.columns else df["Result"].map(parse_time_to_seconds)
    df["Result"] = df["Seconds"].map(seconds_to_mssxx)
    df.to_csv(p, index=False, encoding="utf-8-sig")
    push_to_github(str(p).replace("\\","/"), p.read_bytes(), message)

def append_rows_dedup_and_push(meet_dir: Path, rows: List[dict]):
    base = load_results(meet_dir)
    add = pd.DataFrame(rows, columns=["Name","EventName","Result","Rank","Note","Seconds","Date","City","MeetName","PoolName","LengthMeters"])
    merged = pd.concat([base, add], ignore_index=True)
    # dedup key
    def norm(s: pd.Series) -> pd.Series:
        return s.fillna("").astype(str).str.strip().str.lower()
    key = (
        norm(merged["Name"]) + "|" + norm(merged["EventName"]) + "|" + norm(merged["Result"]) + "|" +
        norm(merged["Date"]) + "|" + norm(merged["City"]) + "|" + norm(merged["MeetName"]) + "|" +
        norm(merged["PoolName"]) + "|" + norm(merged["LengthMeters"])
    )
    merged["__k__"] = key
    merged = merged.drop_duplicates("__k__", keep="first").drop(columns="__k__")
    write_results_and_push(meet_dir, merged, f"Save results for {meet_dir.name}")
    return merged

def delete_indices_and_push(meet_dir: Path, indices: List[int]):
    base = load_results(meet_dir)
    if base.empty or not indices:
        return base
    keep = base.index.difference(indices)
    out = base.loc[keep].reset_index(drop=True)
    write_results_and_push(meet_dir, out, f"Delete rows in {meet_dir.name}")
    return out

# ------------- UI Sections -------------
DEFAULT_EVENTS = [
    "25m Freestyle","50m Freestyle","100m Freestyle","200m Freestyle","400m Freestyle",
    "25m Backstroke","50m Backstroke","100m Backstroke","200m Backstroke",
    "25m Breaststroke","50m Breaststroke","100m Breaststroke","200m Breaststroke",
    "25m Butterfly","50m Butterfly","100m Butterfly","200m Butterfly",
    "100m IM","200m IM","400m IM",
]

def section_meta():
    st.subheader("â‘  æ–°å»º/é€‰æ‹©èµ›äº‹ï¼ˆmetaï¼‰")
    with st.form("meta_form", clear_on_submit=False):
        d = st.date_input("Date", value=date.today(), format="YYYY-MM-DD", key="meta_date")
        city = st.text_input("City", value="Chiang Mai", key="meta_city")
        meet_name = st.text_input("MeetNameï¼ˆå¿…å¡«ï¼‰", value="", key="meta_meet")
        pool_name = st.text_input("PoolNameï¼ˆå¿…å¡«ï¼‰", value="", key="meta_pool")
        length = st.selectbox("LengthMeters", [25,50], index=0, key="meta_len")
        submitted = st.form_submit_button("ä¿å­˜èµ›äº‹ä¿¡æ¯ï¼ˆå†™å…¥/æ¨é€ meta.csvï¼‰")
        if submitted:
            if not meet_name.strip() or not pool_name.strip():
                st.error("âŒ MeetName ä¸ PoolName å¿…å¡«ã€‚")
            else:
                meet_dir = save_meta_and_push(d.isoformat(), city.strip(), meet_name.strip(), pool_name.strip(), int(length))
                st.success(f"âœ… å·²ä¿å­˜å¹¶æ¨é€ï¼š{(meet_dir / 'meta.csv').as_posix()}")

def section_results_and_manage():
    st.subheader("â‘¡ å·²ç™»è®°è®°å½•ï¼ˆå…ˆçœ‹åæ”¹/åˆ ï¼‰ï¼Œç„¶åæ–°å¢æˆç»©")

    meets = list_meets_sorted()
    if not meets:
        st.info("æš‚æ— èµ›äº‹ï¼Œè¯·å…ˆåœ¨ä¸Šæ–¹åˆ›å»º metaã€‚")
        return
    meet_dir = st.selectbox("é€‰æ‹©èµ›äº‹æ–‡ä»¶å¤¹", options=meets, index=0, key="sel_meet", format_func=lambda p: p.name)
    meta = load_meta(meet_dir)

    # ------ Existing records (edit/delete) ------
    df = load_results(meet_dir)
    st.caption("ä¸‹é¢æ˜¯è¯¥èµ›äº‹å·²æœ‰è®°å½•ã€‚å¯ç¼–è¾‘å•å…ƒæ ¼ï¼›è¦åˆ é™¤è¯·å‹¾é€‰â€œåˆ é™¤ï¼Ÿâ€åç‚¹å‡»æŒ‰é’®ã€‚ä¿å­˜å°†å†™å›æœ¬åœ°å¹¶æ¨é€åˆ° GitHubã€‚")
    if df.empty:
        st.info("è¯¥èµ›äº‹æš‚æ— è®°å½•ã€‚")
    else:
        show = df.copy()
        if "åˆ é™¤ï¼Ÿ" not in show.columns:
            show.insert(0, "åˆ é™¤ï¼Ÿ", False)
        show = show.sort_values(by=["Seconds","Name"], ascending=[True, True], na_position="last")
        edited = st.data_editor(
            show,
            key=f"editor_{meet_dir.name}",
            use_container_width=True,
            num_rows="dynamic",
            column_config={
                "åˆ é™¤ï¼Ÿ": st.column_config.CheckboxColumn("åˆ é™¤ï¼Ÿ", help="å‹¾é€‰å¹¶ç‚¹å‡»ä¸‹æ–¹åˆ é™¤æŒ‰é’®")
            }
        )

        c1, c2 = st.columns([1,1])
        with c1:
            if st.button("ğŸ’¾ ä¿å­˜æ›´æ”¹ï¼ˆå†™å›å¹¶æ¨é€ï¼‰", key="btn_save_edits"):
                out = edited.drop(columns=["åˆ é™¤ï¼Ÿ"], errors="ignore")
                write_results_and_push(meet_dir, out, f"Edit results for {meet_dir.name}")
                st.success("å·²ä¿å­˜å¹¶æ¨é€ã€‚")
                safe_rerun()
        with c2:
            if st.button("ğŸ—‘ï¸ åˆ é™¤å‹¾é€‰è¡Œ å¹¶ä¿å­˜ï¼ˆå†™å›å¹¶æ¨é€ï¼‰", key="btn_delete_rows"):
                mask = edited.get("åˆ é™¤ï¼Ÿ", False)
                if isinstance(mask, pd.Series) and mask.any():
                    keep_df = edited.loc[~mask].drop(columns=["åˆ é™¤ï¼Ÿ"], errors="ignore")
                    write_results_and_push(meet_dir, keep_df, f"Delete rows in {meet_dir.name}")
                    st.success(f"å·²åˆ é™¤ {int(mask.sum())} è¡Œå¹¶æ¨é€ã€‚")
                    safe_rerun()
                else:
                    st.info("æœªå‹¾é€‰ä»»ä½•è¡Œã€‚")

    st.markdown("---")
    # ------ Add results ------
    st.subheader("â‘¢ æ–°å¢æˆç»©ï¼ˆresultsï¼‰")

    # event dropdown from defaults + existing
    existing_events = sorted([x for x in df["EventName"].dropna().unique().tolist()]) if not df.empty else []
    ev_options = sorted(set(DEFAULT_EVENTS + existing_events))
    selected_event = st.selectbox("Event é€‰æ‹©", options=ev_options, index=ev_options.index("100m Freestyle") if "100m Freestyle" in ev_options else 0, key="ev_pick")

    rows_n = st.number_input("æœ¬æ¬¡å½•å…¥è¡Œæ•°", min_value=1, max_value=10, value=1, step=1, key="rows_n")
    # ensure keys exist to avoid state errors
    for i in range(1, int(rows_n)+1):
        for f in ("Name","EventName","Result","Rank","Note"):
            st.session_state.setdefault(f"{f}_{i}", "")

    inputs = []
    for i in range(1, int(rows_n)+1):
        st.markdown(f"**è®°å½• {i}**")
        c1, c2, c3, c4 = st.columns([1.2,1.4,1.0,1.4])
        name = c1.text_input(f"Name_{i}", key=f"Name_{i}", value=st.session_state.get(f"Name_{i}", "Anna"), placeholder="é€‰æ‰‹å")
        event_name = c2.text_input(f"EventName_{i}", key=f"EventName_{i}", value=selected_event)
        result = c3.text_input(f"Result_{i}", key=f"Result_{i}", placeholder="34.12 æˆ– 0:34.12")
        rank = c4.text_input(f"Rank_{i}ï¼ˆå¯ç©ºï¼‰", key=f"Rank_{i}", value="")
        note = st.text_input(f"Note_{i}", key=f"Note_{i}", placeholder="å¯ç•™ç©º")
        inputs.append((name, event_name, result, rank, note))

    if st.button("ä¿å­˜è¿™äº›æˆç»©ï¼ˆå†™å›å¹¶æ¨é€ï¼‰", type="primary", key="btn_save_new"):
        rows = []
        for (name, ev, res, rk, note) in inputs:
            if not str(name).strip() or not str(ev).strip() or not str(res).strip():
                continue
            secs = parse_time_to_seconds(str(res))
            if secs is None:
                st.warning(f"æ—¶é—´æ ¼å¼ä¸åˆæ³•ï¼š{res}ï¼ˆå·²è·³è¿‡ï¼‰")
                continue
            rows.append({
                "Name": str(name).strip(),
                "EventName": str(ev).strip(),
                "Result": seconds_to_mssxx(secs),
                "Rank": str(rk).strip() if str(rk).strip() else "",
                "Note": str(note).strip(),
                "Seconds": secs,
                "Date": str(meta.get('Date','')),
                "City": str(meta.get('City','')),
                "MeetName": str(meta.get('MeetName','')),
                "PoolName": str(meta.get('PoolName','')),
                "LengthMeters": int(meta.get('LengthMeters', 25)) if str(meta.get('LengthMeters','')).strip() else 25,
            })
        if not rows:
            st.info("æ²¡æœ‰æœ‰æ•ˆè¡Œå¯ä¿å­˜ã€‚")
        else:
            append_rows_dedup_and_push(meet_dir, rows)
            st.success(f"å·²ä¿å­˜å¹¶æ¨é€åˆ° GitHubï¼š{(meet_dir/'results.csv').as_posix()}")
            # clear inputs
            for i in range(1, int(rows_n)+1):
                for f in ("Name","EventName","Result","Rank","Note"):
                    st.session_state.pop(f"{f}_{i}", None)
            safe_rerun()

# --------- Query page ---------
def page_query():
    st.header("ğŸ” æˆç»©æŸ¥è¯¢ / å¯¹æ¯”")
    frames = []
    for d in list_meets_sorted():
        p = d / "results.csv"
        if p.exists():
            try:
                df = pd.read_csv(p)
                frames.append(df)
            except Exception:
                pass
    if not frames:
        st.info("æš‚æ— æ•°æ®ã€‚")
        return
    data = pd.concat(frames, ignore_index=True)
    if "Seconds" in data.columns:
        data["Seconds"] = data["Seconds"].where(data["Seconds"].notna(), data["Result"].map(parse_time_to_seconds))
    else:
        data["Seconds"] = data["Result"].map(parse_time_to_seconds)
    data["Result"] = data["Seconds"].map(seconds_to_mssxx)

    names = sorted([x for x in data["Name"].dropna().unique().tolist() if str(x).strip()])
    events = ["å…¨éƒ¨"] + sorted([x for x in data["EventName"].dropna().unique().tolist() if str(x).strip()])
    lengths = ["å…¨éƒ¨"] + [str(int(x)) for x in pd.to_numeric(data["LengthMeters"], errors="coerce").dropna().unique().tolist()]

    pick_names = st.multiselect("Nameï¼ˆå¯å¤šé€‰ï¼‰", names, default=names[:1] if names else [])
    pick_event = st.selectbox("Event", events, index=0)
    pick_len = st.selectbox("Length (Meters)", lengths, index=0)

    q = data.copy()
    if pick_names:
        q = q[q["Name"].isin(pick_names)]
    if pick_event != "å…¨éƒ¨":
        q = q[q["EventName"] == pick_event]
    if pick_len != "å…¨éƒ¨":
        # å¼ºå¥çš„æ³³æ± é•¿åº¦ç­›é€‰ï¼ˆå…¼å®¹ 25/50 å’Œ 25.0/50.0 ç­‰ï¼‰
        try:
            pick_len_int = int(pick_len)
            q = q[pd.to_numeric(q["LengthMeters"], errors="coerce").round().astype("Int64") == pick_len_int]
        except Exception:
            pass

    q = q.sort_values(by=["Seconds","Date","Name"], ascending=[True, True, True])
    show_cols = ["Name","Date","EventName","Result","Rank","Note","City","PoolName","LengthMeters","MeetName"]
    show_cols = [c for c in show_cols if c in q.columns]
    st.dataframe(q[show_cols], use_container_width=True, hide_index=True)

# ---------------- Main ----------------
def main():
    st.title(APP_TITLE)
    tab1, tab2 = st.tabs(["èµ›äº‹ç®¡ç† / æˆç»©å½•å…¥", "æŸ¥è¯¢ / å¯¹æ¯”"])
    with tab1:
        section_meta()
        st.markdown("---")
        section_results_and_manage()
    with tab2:
        page_query()

if __name__ == "__main__":
    main()
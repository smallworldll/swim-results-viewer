
import os
import io
import json
import base64
import requests
import datetime as dt
from pathlib import Path

import pandas as pd
import streamlit as st

# ---------------------------
# Config
# ---------------------------
st.set_page_config(page_title="æ¸¸æ³³æˆç»©ç³»ç»Ÿï¼ˆèµ›äº‹åˆ¶ï¼‰", layout="wide")

MEETS_ROOT = Path("meets")  # relative to repo root

# Standard events for dropdowns
STANDARD_EVENTS = [
    "25m Freestyle", "25m Backstroke", "25m Breaststroke", "25m Butterfly",
    "50m Freestyle", "50m Backstroke", "50m Breaststroke", "50m Butterfly",
    "100m Freestyle", "100m Backstroke", "100m Breaststroke", "100m Butterfly",
    "200m Freestyle", "200m Backstroke", "200m Breaststroke", "200m Butterfly",
    "200m IM", "400m Freestyle", "400m IM"
]

# ---------------------------
# Helpers
# ---------------------------

def ensure_meets_root():
    MEETS_ROOT.mkdir(exist_ok=True)

def meet_folder_name(date_str: str, city: str, poolname: str) -> str:
    # 2025-08-09_Chiang Mai_National Sports University Chiang Mai Campus
    safe_city = city.replace("/", "_").strip()
    safe_pool = poolname.replace("/", "_").strip()
    return f"{date_str}_{safe_city}_{safe_pool}"

def parse_time_to_display_and_seconds(s: str):
    """Accept '34.12' or '0:34.12' or '1:02.45'. Return ('m:ss.xx', seconds float)."""
    s = (s or "").strip()
    if not s:
        return "", None
    # normalize decimals
    try:
        if ":" in s:
            # m:ss.xx
            parts = s.split(":")
            if len(parts) == 2:
                m = int(parts[0])
                sec = float(parts[1])
            else:
                # h:mm:ss.xx -> convert to minutes
                h = int(parts[0])
                m = int(parts[1]) + 60 * h
                sec = float(parts[2])
        else:
            # "34.12" -> 0:34.12
            m = 0
            sec = float(s)
        total = m * 60 + sec
        # format
        mm = int(total // 60)
        ss = total - mm * 60
        display = f"{mm}:{ss:05.2f}"
        return display, round(total, 2)
    except Exception:
        return s, None

def gh_headers():
    token = st.secrets.get("GITHUB_TOKEN", "")
    return {
        "Authorization": f"token {token}",
        "Accept": "application/vnd.github+json"
    }

def gh_repo():
    return st.secrets.get("REPO", "")  # e.g., "smallworlddll/swim-results-viewer"

def gh_api_url(path: str):
    return f"https://api.github.com/repos/{gh_repo()}/contents/{path}"

def push_to_github(path: str, content_bytes: bytes, commit_message: str):
    """Create or update a file via GitHub API. Always attempt when token/repo present."""
    repo = gh_repo()
    token = st.secrets.get("GITHUB_TOKEN", "")
    if not repo or not token:
        # show a gentle warn
        st.info("âš ï¸ æœªé…ç½® GITHUB_TOKEN/REPOï¼Œå·²è·³è¿‡ GitHub æ¨é€ï¼ˆæœ¬åœ°å·²ä¿å­˜ï¼‰ã€‚")
        return False, "NO_SECRET"

    url = gh_api_url(path)
    headers = gh_headers()

    # Check if exists to get sha
    resp = requests.get(url, headers=headers)
    sha = None
    if resp.status_code == 200:
        try:
            sha = resp.json().get("sha")
        except Exception:
            sha = None

    payload = {
        "message": commit_message,
        "content": base64.b64encode(content_bytes).decode("utf-8"),
        "branch": "main"
    }
    if sha:
        payload["sha"] = sha

    put = requests.put(url, headers=headers, data=json.dumps(payload))
    if put.status_code in (200, 201):
        return True, "OK"
    else:
        try:
            msg = put.json()
        except Exception:
            msg = {"status": put.status_code, "text": put.text}
        st.warning(f"GitHub æ¨é€å¤±è´¥: {msg}")
        return False, msg

def read_csv_if_exists(path: Path, **kwargs) -> pd.DataFrame:
    if path.exists():
        try:
            return pd.read_csv(path, **kwargs)
        except Exception:
            return pd.DataFrame()
    return pd.DataFrame()

def write_csv(df: pd.DataFrame, path: Path):
    path.parent.mkdir(parents=True, exist_ok=True)
    df.to_csv(path, index=False, encoding="utf-8-sig")

def list_meets():
    ensure_meets_root()
    items = []
    for p in sorted(MEETS_ROOT.glob("*")):
        if not p.is_dir():
            continue
        meta = p / "meta.csv"
        row = {"folder": p.name}
        if meta.exists():
            try:
                m = pd.read_csv(meta)
                if not m.empty:
                    row.update(m.iloc[0].to_dict())
            except Exception:
                pass
        items.append(row)
    # sort by Date desc
    def _key(x):
        d = x.get("Date") or ""
        try:
            return dt.datetime.strptime(d, "%Y-%m-%d")
        except Exception:
            return dt.datetime.min
    items.sort(key=_key, reverse=True)
    return items

def load_meet_results(folder: str) -> pd.DataFrame:
    path = MEETS_ROOT / folder / "results.csv"
    df = read_csv_if_exists(path)
    return df

def load_meet_meta(folder: str) -> pd.Series:
    path = MEETS_ROOT / folder / "meta.csv"
    m = read_csv_if_exists(path)
    if m.empty:
        return pd.Series(dtype=object)
    return m.iloc[0]

def build_event_options(existing_df: pd.DataFrame) -> list:
    options = list(STANDARD_EVENTS)
    if not existing_df.empty and "EventName" in existing_df.columns:
        extra = [x for x in existing_df["EventName"].dropna().unique().tolist() if x not in options]
        options.extend(extra)
    return options

def add_rows_and_save(folder: str, rows: list):
    """rows: list of dicts with required fields"""
    df = load_meet_results(folder)
    base_cols = [
        "Name", "EventName", "Result", "Rank", "Note",
        "Seconds", "Date", "City", "MeetName", "PoolName", "LengthMeters"
    ]
    if df.empty:
        df = pd.DataFrame(columns=base_cols)
    # Append
    add_df = pd.DataFrame(rows, columns=base_cols)
    # Deduplicate on a set of columns to avoid accidental duplicate save clicks
    subset = ["Name", "EventName", "Result", "Date", "City", "MeetName", "PoolName", "LengthMeters"]
    merged = pd.concat([df, add_df], ignore_index=True)
    merged = merged.drop_duplicates(subset=subset, keep="first")
    # Sort (optional) by Seconds asc if present
    if "Seconds" in merged.columns:
        merged = merged.sort_values(by=["EventName", "Seconds"], ascending=[True, True], na_position="last")
    # Save local
    local_path = MEETS_ROOT / folder / "results.csv"
    write_csv(merged, local_path)
    # Push GitHub
    with open(local_path, "rb") as f:
        ok, msg = push_to_github(str(local_path).replace("\\", "/"), f.read(), f"Save results for {folder}")
    return merged, ok

def delete_selected_and_save(folder: str, indices: list):
    df = load_meet_results(folder)
    if df.empty or not indices:
        return df, False
    keep = df.index.difference(indices)
    new_df = df.loc[keep].reset_index(drop=True)
    local_path = MEETS_ROOT / folder / "results.csv"
    write_csv(new_df, local_path)
    with open(local_path, "rb") as f:
        ok, msg = push_to_github(str(local_path).replace("\\", "/"), f.read(), f"Delete rows in {folder}")
    return new_df, ok

def save_meta_and_push(date_str: str, city: str, meetname: str, poolname: str, length: int):
    folder = meet_folder_name(date_str, city, poolname)
    meta_path = MEETS_ROOT / folder / "meta.csv"
    row = {
        "Date": date_str,
        "City": city,
        "MeetName": meetname,
        "PoolName": poolname,
        "LengthMeters": int(length)
    }
    write_csv(pd.DataFrame([row]), meta_path)
    with open(meta_path, "rb") as f:
        ok, msg = push_to_github(str(meta_path).replace("\\", "/"), f.read(), f"Save meta for {folder}")
    return folder, ok

# ---------------------------
# UI Sections
# ---------------------------

def section_meta():
    st.markdown("## ğŸ—‚ï¸ â‘  æ–°å»º/é€‰æ‹©èµ›äº‹ï¼ˆmetaï¼‰")

    today = dt.date.today().strftime("%Y-%m-%d")
    col1, col2, col3 = st.columns([1,1,1])
    with col1:
        date_str = st.text_input("Date", value=today)
    with col2:
        city = st.text_input("City", value="Chiang Mai")
    with col3:
        length = st.selectbox("LengthMeters", options=[25,50], index=0)

    meetname = st.text_input("MeetNameï¼ˆå¿…å¡«ï¼‰", value="")
    poolname = st.text_input("PoolNameï¼ˆå¿…å¡«ï¼‰", value="")

    if st.button("ä¿å­˜èµ›äº‹ä¿¡æ¯ï¼ˆå†™å…¥/æ¨é€ meta.csvï¼‰", type="primary"):
        if not meetname.strip() or not poolname.strip():
            st.error("MeetName ä¸ PoolName å‡ä¸ºå¿…å¡«ã€‚")
        else:
            folder, ok = save_meta_and_push(date_str, city, meetname.strip(), poolname.strip(), length)
            st.success(f"å·²ä¿å­˜ï¼š{MEETS_ROOT / folder / 'meta.csv'}")

def section_results_entry_and_manage():
    st.markdown("## ğŸ“ â‘¡ æ–°å¢æˆç»© / ç®¡ç†")
    meets = list_meets()
    folders = [x["folder"] for x in meets] if meets else []
    if not folders:
        st.info("å½“å‰æ²¡æœ‰èµ›äº‹ï¼Œè¯·å…ˆåœ¨ä¸Šæ–¹åˆ›å»ºèµ›äº‹ã€‚")
        return
    # é»˜è®¤é€‰æ‹©æœ€è¿‘ï¼ˆåˆ—è¡¨å·²æŒ‰æ—¥æœŸå€’åºï¼‰
    folder = st.selectbox("é€‰æ‹©èµ›äº‹æ–‡ä»¶å¤¹", options=folders, index=0)
    meta = load_meet_meta(folder)
    # Show existing first
    st.markdown("### â‘¢ å·²ç™»è®°è®°å½•ï¼ˆå¯ç¼–è¾‘/åˆ é™¤ï¼‰")
    df_exist = load_meet_results(folder)
    if df_exist.empty:
        st.info("æœ¬èµ›äº‹æš‚æ— è®°å½•ã€‚")
    else:
        # Allow multi-select delete
        # show essential columns
        show_cols = ["Name", "EventName", "Result", "Rank", "Note", "Seconds", "Date", "City", "MeetName", "PoolName", "LengthMeters"]
        for c in show_cols:
            if c not in df_exist.columns:
                df_exist[c] = ""
        # Use selection box for indices
        st.caption("å‹¾é€‰éœ€è¦åˆ é™¤çš„è®°å½•ï¼ˆæ”¯æŒå¤šé€‰ï¼‰ï¼Œç„¶åç‚¹å‡»ä¸‹æ–¹â€œåˆ é™¤é€‰ä¸­å¹¶ä¿å­˜â€ã€‚")
        selected = st.dataframe(df_exist[show_cols], use_container_width=True)
        # Provide multi-select by indices via text input for now (Streamlit's DF selection is limited)
        del_idxs_text = st.text_input("è¦åˆ é™¤çš„è¡Œå·ï¼ˆç”¨é€—å·åˆ†éš”ï¼Œä¾‹å¦‚ï¼š2,5,7ï¼‰", value="")
        if st.button("ğŸ—‘ï¸ åˆ é™¤é€‰ä¸­å¹¶ä¿å­˜ï¼ˆå†™å…¥ results.csv å¹¶æ¨é€ GitHubï¼‰"):
            try:
                idxs = [int(x.strip())-1 for x in del_idxs_text.split(",") if x.strip().isdigit()]
            except Exception:
                idxs = []
            new_df, ok = delete_selected_and_save(folder, idxs)
            st.success("å·²åˆ é™¤å¹¶ä¿å­˜ï¼ˆæœ¬åœ° & GitHubï¼‰ã€‚")
            st.experimental_rerun()

    st.markdown("---")
    st.markdown("### â‘£ æ–°å¢æˆç»©")
    # build event options
    event_options = build_event_options(df_exist)
    default_event = event_options[0] if event_options else "50m Freestyle"
    event_selected = st.selectbox("Event é€‰æ‹©", options=event_options, index=event_options.index(default_event) if default_event in event_options else 0)

    rows = st.number_input("æœ¬æ¬¡å½•å…¥è¡Œæ•°", min_value=1, max_value=10, value=1, step=1)
    inputs = []
    for i in range(1, rows+1):
        st.markdown(f"#### è®°å½• {i}")
        c1, c2, c3, c4 = st.columns([1,1,1,1])
        with c1:
            name = st.text_input(f"Name_{i}", value="")
        with c2:
            eventname = st.text_input(f"EventName_{i}", value=event_selected)
        with c3:
            result = st.text_input(f"Result_{i}", value="")
        with c4:
            rank = st.text_input(f"Rank_{i}", value="")
        note = st.text_input(f"Note_{i}", value="å¯ç•™ç©º")
        inputs.append({"Name": name, "EventName": eventname, "Result": result, "Rank": rank, "Note": note})

    if st.button("ä¿å­˜è¿™äº›æˆç»©ï¼ˆå†™å…¥ results.csv å¹¶æ¨é€ GitHubï¼‰", type="primary"):
        # prepare rows
        if meta.empty:
            st.error("æœªæ‰¾åˆ°èµ›äº‹ metaï¼Œè¯·è¿”å›ä¸Šæ–¹ä¿å­˜èµ›äº‹ä¿¡æ¯ã€‚")
        else:
            prepared = []
            for r in inputs:
                if not r["Name"].strip() or not r["EventName"].strip() or not r["Result"].strip():
                    # skip incomplete
                    continue
                display, secs = parse_time_to_display_and_seconds(r["Result"])
                row = {
                    "Name": r["Name"].strip(),
                    "EventName": r["EventName"].strip(),
                    "Result": display if display else r["Result"].strip(),
                    "Rank": r["Rank"].strip() if r["Rank"] is not None else "",
                    "Note": r["Note"].strip() if r["Note"] else "",
                    "Seconds": secs,
                    "Date": meta.get("Date", ""),
                    "City": meta.get("City", ""),
                    "MeetName": meta.get("MeetName", ""),
                    "PoolName": meta.get("PoolName", ""),
                    "LengthMeters": meta.get("LengthMeters", "")
                }
                prepared.append(row)
            if not prepared:
                st.warning("æ²¡æœ‰å¯ä¿å­˜çš„å®Œæ•´è®°å½•ï¼ˆName / Event / Result å¿…å¡«ï¼‰ã€‚")
            else:
                merged, ok = add_rows_and_save(folder, prepared)
                st.success(f"å·²ä¿å­˜ {len(prepared)} æ¡åˆ° {MEETS_ROOT / folder / 'results.csv'}ï¼ˆå¹¶å·²æ¨é€ï¼‰ã€‚")
                # clear inputs by rerun
                st.experimental_rerun()

def section_query():
    st.markdown("## ğŸ” â‘¤ æˆç»©æŸ¥è¯¢ / å¯¹æ¯”")
    # gather all results
    ensure_meets_root()
    all_rows = []
    for p in MEETS_ROOT.glob("*/*"):
        if p.name == "results.csv":
            df = read_csv_if_exists(p)
            if not df.empty:
                all_rows.append(df)
    if not all_rows:
        st.info("æœªæ‰¾åˆ°ä»»ä½•æˆç»©æ•°æ®ã€‚")
        return
    data = pd.concat(all_rows, ignore_index=True)
    # filters
    names = sorted([x for x in data["Name"].dropna().unique().tolist() if str(x).strip()])
    name_sel = st.multiselect("Nameï¼ˆå¯å¤šé€‰ï¼‰", names, default=names[:1] if names else [])
    events_all = sorted([x for x in data["EventName"].dropna().unique().tolist() if str(x).strip()])
    event_sel = st.selectbox("Event", options=["å…¨éƒ¨"] + events_all, index=0)
    len_options = sorted([int(x) for x in data["LengthMeters"].dropna().unique().tolist()])
    length_sel = st.selectbox("Length (Meters)", options=["å…¨éƒ¨"] + len_options, index=0)

    df = data.copy()
    if name_sel:
        df = df[df["Name"].isin(name_sel)]
    if event_sel != "å…¨éƒ¨":
        df = df[df["EventName"] == event_sel]
    if length_sel != "å…¨éƒ¨":
        df = df[df["LengthMeters"] == length_sel]

    # order by Seconds asc
    if "Seconds" in df.columns:
        df = df.sort_values(by=["Seconds"], ascending=[True], na_position="last")

    st.dataframe(df, use_container_width=True)

# ---------------------------
# Main
# ---------------------------

def main():
    st.title("ğŸŠ æ¸¸æ³³æˆç»©ç³»ç»Ÿï¼ˆèµ›äº‹åˆ¶ï¼‰")
    section_meta()
    st.divider()
    section_results_entry_and_manage()
    st.divider()
    section_query()

if __name__ == "__main__":
    main()
